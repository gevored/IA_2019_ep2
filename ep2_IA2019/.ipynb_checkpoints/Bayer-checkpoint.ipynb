{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas \n",
    "from pandas import DataFrame  as df\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import train_test_split\n",
    "from math import log\n",
    "import math\n",
    "from decimal import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['time' 'android.sensor.accelerometer#mean'\n",
      " 'android.sensor.accelerometer#max' 'android.sensor.accelerometer#std'\n",
      " 'android.sensor.game_rotation_vector#mean'\n",
      " 'android.sensor.linear_acceleration#mean' 'sound#mean' 'speed#mean'\n",
      " 'speed#min' 'speed#max']\n"
     ]
    }
   ],
   "source": [
    "#leitura da base e definição dos campos utilizados\n",
    "#baseTotalAtributos = pandas.read_csv (r\"C:\\Users\\Gerson\\Desktop\\EP2_ia2019\\dataset_5secondWindow%5B3%5D.csv\", usecols =  [\"time\",\"android.sensor.accelerometer#mean\",\"android.sensor.linear_acceleration#mean\",\"android.sensor.orientation#mean\",\"speed#mean\"])\n",
    "baseTotalAtributos = pandas.read_csv (r\"C:\\Users\\Gerson\\Desktop\\EP2_ia2019\\dataset_5secondWindow%5B3%5D.csv\", usecols =  [\"time\",\"android.sensor.accelerometer#max\", \"speed#max\" , \"speed#min\",\"android.sensor.accelerometer#std\",\"android.sensor.accelerometer#mean\",\"android.sensor.linear_acceleration#mean\",\"android.sensor.game_rotation_vector#mean\", \"android.sensor.accelerometer#std\" ,\"sound#mean\", \"speed#mean\"])\n",
    "\n",
    "baseTotalClasse = pandas.read_csv (r\"C:\\Users\\Gerson\\Desktop\\EP2_ia2019\\dataset_5secondWindow%5B3%5D.csv\", usecols = [\"target\"])\n",
    "\n",
    "print(baseTotalAtributos.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#normalização por padronização \n",
    "def normalizacaoLinear(baseTotalAtr):\n",
    "    colunas =  list(baseTotalAtr.columns)\n",
    "\n",
    "    baseTotalAtributosNorm = baseTotalAtr.copy()\n",
    "    baseTotalAtributosNorm[colunas] = baseTotalAtr[colunas].apply(scale)\n",
    "    \n",
    "    return baseTotalAtributosNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#discretização dos dados\n",
    "def discretizacaoBase(baseAtributos,qtdParte):\n",
    "    \n",
    "    baseDiscretizada = pandas.DataFrame()\n",
    "    for coluna in baseAtributos.columns.values:\n",
    "        baseDiscretizada[coluna] = pandas.cut(baseAtributos[coluna],bins = qtdParte,labels= range(qtdParte))  \n",
    "    return baseDiscretizada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Bayer(baseTreinamento , baseTeste):\n",
    "    \n",
    "    totalRegistros = len(baseTreinamento)\n",
    "    classes, counts_elements = np.unique(baseTreinamento['target'], return_counts=True )     \n",
    "    \n",
    "    colunas = baseTreinamento.columns.drop('target')\n",
    "    tabelaMetricas = pandas.DataFrame(columns = ['coluna','classe','dominio','qDominios', 'qClasses','probabilidade' ])\n",
    "\n",
    "    #treinamento ( montando uma tabela de métricas)\n",
    "    for coluna in colunas:\n",
    "        dominios =  baseTreinamento[coluna].unique()\n",
    "        \n",
    "        for dominio in dominios:\n",
    "            for classe in classes:\n",
    "                qtdDominioClasse   = len(baseTreinamento[(baseTreinamento[coluna]==dominio) & (baseTreinamento.target == classe)])\n",
    "                qtdClasse  = len(baseTreinamento[baseTreinamento['target'] == classe ])\n",
    "                p = qtdDominioClasse /qtdClasse   \n",
    "                \n",
    "                # caso alguma probabilidade seja 0, substituir por 0.00001 para que a multiplicação não resulte em 0\n",
    "                if (p == 0):\n",
    "                    p = 0.00001\n",
    "                tabelaMetricas = tabelaMetricas.append ({'coluna':coluna,'classe':classe ,'dominio':dominio,'qDominios':qtdDominioClasse , 'qClasses':qtdClasse , 'probabilidade':p},ignore_index=True)\n",
    "    \n",
    "    #armazenando quantos registros há por classe\n",
    "    qtdExemplosPorClasse = {}\n",
    "    for i in range (len(classes)):\n",
    "        qtdExemplosPorClasse[classes[i]] = counts_elements[i]\n",
    "    \n",
    "    \n",
    "    classificacao = {}\n",
    "    somatorio = 0\n",
    "    probParcialClasses = {}\n",
    "    for index, exemplo in baseTeste.iterrows():\n",
    "        \n",
    "        for classe in classes: \n",
    "            prob = 1            \n",
    "            p2 =  qtdExemplosPorClasse[classe]/totalRegistros\n",
    "            \n",
    "            for coluna in colunas:\n",
    "                dominio = exemplo[coluna]\n",
    "                p = float(tabelaMetricas [(tabelaMetricas['coluna'] == coluna) & (tabelaMetricas['dominio'] == dominio) & (tabelaMetricas['classe'] == classe)]['probabilidade'])\n",
    "               \n",
    "                prob =  prob*p\n",
    "                \n",
    "            probParcialClasses[classe] = prob\n",
    "            somatorio += prob\n",
    "    \n",
    "        votacaoClasse = { }\n",
    "        for c in probParcialClasses :\n",
    "            votacaoClasse[c] = probParcialClasses[c]/somatorio\n",
    "        classificacao[index] = max(votacaoClasse, key = votacaoClasse.get)\n",
    "    \n",
    "    return classificacao\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "atributosNormalizados = normalizacaoLinear(baseTotalAtributos)\n",
    "\n",
    "#particionamento da base 70 % para o conjunto de teste e 30 % para o conjunto de treinamento\n",
    "baseTreinoNorm,  baseTesteNorm , classeTreinoNorm, classeTesteNorm = train_test_split(atributosNormalizados, baseTotalClasse, test_size = 0.3 , train_size = 0.7, random_state = 0)\n",
    "baseTreinoNaoNorm,  baseTesteNaoNorm , classeTreinoNaoNorm, classeTesteNaoNorm = train_test_split(baseTotalAtributos, baseTotalClasse, test_size = 0.3 , train_size = 0.7, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#DISCRETIZACAO DOS DADOS NORMALIZADOS E CONTINUOS\n",
    "baseTreinamentoDiscretizadaNormalizada = discretizacaoBase(baseTreinoNorm,6)\n",
    "baseTesteDiscretizadaNormalizada = discretizacaoBase(baseTesteNorm,6)\n",
    "\n",
    "baseTreinamentoDiscretizadaNAONormalizada = discretizacaoBase(baseTreinoNaoNorm,6)\n",
    "baseTesteDiscretizadaNAONormalizada = discretizacaoBase(baseTesteNaoNorm,6)\n",
    "\n",
    "#ANEXAR A CLASSE DAS BASES UTILIZADAS ( TESTE E TREINAMENTO)\n",
    "mergeTreinamentoNormalizada = baseTreinamentoDiscretizadaNormalizada.merge(classeTreinoNorm, left_index=True, right_index=True, how='inner')\n",
    "mergeTesteNormalizada = baseTesteDiscretizadaNormalizada.merge(classeTesteNorm, left_index=True, right_index=True, how='inner')\n",
    "\n",
    "mergeTreinamentoNAONormalizada = baseTreinamentoDiscretizadaNAONormalizada.merge(baseTotalClasse, left_index=True, right_index=True, how='inner')\n",
    "mergeTesteNAONormalizada = baseTesteDiscretizadaNAONormalizada.merge(baseTotalClasse, left_index=True, right_index=True, how='inner')\n",
    "\n",
    "#INVOCAR A FUNÇAO DE CLASSIFIÇACAO\n",
    "setTesteNormalizado = Bayer(mergeTreinamentoNormalizada, mergeTesteNormalizada)\n",
    "setTesteNAONormalizado = Bayer(mergeTreinamentoNAONormalizada, mergeTesteNAONormalizada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acuraciaKNN(setTeste,baseTotalClasse):\n",
    "    acertos = 0 \n",
    "    for i  in setTeste:\n",
    "        if (setTeste[i] == baseTotalClasse['target'][i] ):\n",
    "            acertos += 1\n",
    "    print(acertos/len(setTeste))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4089366515837104\n",
      "0.4089366515837104\n"
     ]
    }
   ],
   "source": [
    "acuraciaKNN(setTesteNormalizado, baseTotalClasse)\n",
    "acuraciaKNN(setTesteNAONormalizado, baseTotalClasse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verificando robustez \n",
    "def mudarClasse(baseClasseTreinamento , classesDistintas,test,train):\n",
    "    \n",
    "    baseTempClasseTreinamento =  baseClasseTreinamento.copy()\n",
    "\n",
    "    base_ruido ,base_nao_ruido =train_test_split(baseTempClasseTreinamento,test_size = test,  train_size = train , random_state = 0)\n",
    "   \n",
    "  \n",
    "    for index,classe in base_ruido.iterrows():\n",
    "        classesDistintasTemp = classesDistintas\n",
    "        i =  np.where(classesDistintasTemp == classe['target'])\n",
    "      \n",
    "        \n",
    "        classesDistintasTemp = np.delete(classesDistintasTemp,i)\n",
    "       \n",
    "        baseTempClasseTreinamento['target'][index] =  np.random.choice(classesDistintasTemp,1)[0]\n",
    "       \n",
    "        #print(np.random.choice(classesDistintasTemp,1)[0], type(np.random.choice(classesDistintasTemp,1)))\n",
    "  \n",
    "    return  baseTempClasseTreinamento \n",
    "classDistinct = baseTotalClasse['target'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4751131221719457\n"
     ]
    }
   ],
   "source": [
    "#5%\n",
    "classe5 = mudarClasse(classeTreinoNorm, classDistinct, 0.95 ,0.05 )\n",
    "mergeTreinamento5 = baseTreinamentoDiscretizadaNormalizada.merge(classe5, left_index=True, right_index=True, how='inner')\n",
    "setTeste5 = Bayer(mergeTreinamento5, mergeTesteNormalizada)\n",
    "acuraciaKNN (setTeste5, baseTotalClasse )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4751131221719457\n"
     ]
    }
   ],
   "source": [
    "#10%\n",
    "classe10 = mudarClasse(classeTreinoNorm, classDistinct, 0.9 ,0.1 )\n",
    "mergeTreinamento10 = baseTreinamentoDiscretizadaNormalizada.merge(classe5, left_index=True, right_index=True, how='inner')\n",
    "setTeste10 = Bayer(mergeTreinamento10, mergeTesteNormalizada)\n",
    "acuraciaKNN (setTeste10, baseTotalClasse )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4751131221719457\n"
     ]
    }
   ],
   "source": [
    "#15%\n",
    "classe15 = mudarClasse(classeTreinoNorm, classDistinct, 0.85 ,0.15  )\n",
    "mergeTreinamento15 = baseTreinamentoDiscretizadaNormalizada.merge(classe5, left_index=True, right_index=True, how='inner')\n",
    "setTeste15 = Bayer(mergeTreinamento15, mergeTesteNormalizada)\n",
    "acuraciaKNN (setTeste15, baseTotalClasse )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4751131221719457\n"
     ]
    }
   ],
   "source": [
    "#20%\n",
    "classe20 = mudarClasse(classeTreinoNorm, classDistinct, 0.8 ,0.2  )\n",
    "mergeTreinamento20 = baseTreinamentoDiscretizadaNormalizada.merge(classe5, left_index=True, right_index=True, how='inner')\n",
    "setTeste20 = Bayer(mergeTreinamento20, mergeTesteNormalizada)\n",
    "acuraciaKNN (setTeste20, baseTotalClasse )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4751131221719457\n"
     ]
    }
   ],
   "source": [
    "#25%\n",
    "classe25 = mudarClasse(classeTreinoNorm, classDistinct,0.75 ,0.25  )\n",
    "mergeTreinamento25 = baseTreinamentoDiscretizadaNormalizada.merge(classe5, left_index=True, right_index=True, how='inner')\n",
    "setTeste25 = Bayer(mergeTreinamento25, mergeTesteNormalizada)\n",
    "acuraciaKNN (setTeste25, baseTotalClasse )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4089366515837104\n"
     ]
    }
   ],
   "source": [
    "#90%\n",
    "classe25 = mudarClasse(classeTreinoNorm, classDistinct,0.1 ,0.9  )\n",
    "mergeTreinamento25 = baseTreinamentoDiscretizadaNormalizada.merge(classe5, left_index=True, right_index=True, how='inner')\n",
    "setTeste25 = Bayer(mergeTreinamentoNormalizada, mergeTesteNormalizada)\n",
    "acuraciaKNN (setTeste25, baseTotalClasse )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
